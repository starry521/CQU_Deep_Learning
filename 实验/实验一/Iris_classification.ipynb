{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7904c6ff-5217-4e09-9d10-36cddbb80d21",
   "metadata": {},
   "source": [
    "导入模块和定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56f54b6e-fe26-422e-a4ab-b416a8555fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "import mindspore\n",
    "from mindspore import nn\n",
    "from mindspore import context\n",
    "from mindspore import dataset\n",
    "from mindspore.train.callback import TimeMonitor, LossMonitor\n",
    "from mindspore import Tensor\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "# 设定运行模式为静态图模式，并且运行设备为昇腾芯片\n",
    "\n",
    "# 变量定义\n",
    "cfg = edict({\n",
    "    'data_size': 150,\n",
    "    'train_size': 120,      # 训练集大小\n",
    "    'test_size': 30 ,       # 测试集大小\n",
    "    'feature_number': 4,       # 输入特征数\n",
    "    'num_class': 3,     # 分类类别\n",
    "    'batch_size': 30,\n",
    "    'data_dir':    './iris.data',                     \n",
    "    'save_checkpoint_steps': 5,                 # 多少步保存一次模型\n",
    "    'keep_checkpoint_max': 1,                      # 最多保存多少个模型\n",
    "    'out_dir_no_opt':   './model_iris/no_opt',          # 保存模型路径，无优化器模型\n",
    "    'out_dir_sgd':   './model_iris/sgd',          # 保存模型路径,SGD优化器模型\n",
    "    'out_dir_momentum':   './model_iris/momentum',          # 保存模型路径，momentum模型\n",
    "    'out_dir_adam':   './model_iris/adam',          # 保存模型路径，adam优化器模型\n",
    "    'output_prefix': \"checkpoint_fashion_forward\"     # 保存模型文件名\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86b939-53c4-4fb7-918d-128be386df98",
   "metadata": {},
   "source": [
    " 读取数据并预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e47a85-1e26-4203-bf23-e610392c7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取鸢尾花数据集，本数据集共有150个带标签的数据\n",
    "with open(cfg.data_dir) as csv_file:\n",
    "    data = list(csv.reader(csv_file, delimiter=','))\n",
    "\n",
    "# 共150条数据，将数据集的4个属性作为自变量X。将数据集的3个类别映射为{0, 1，2}，作为因变量Y\n",
    "label_map = {'Iris-setosa': 0,'Iris-versicolor': 1,'Iris-virginica':2 }\n",
    "# 分别获取数据中的特征值X和标签值Y\n",
    "X = np.array([[float(x) for x in s[:-1]] for s in data[:cfg.data_size]], np.float32)\n",
    "Y = np.array([label_map[s[-1]] for s in data[:cfg.data_size]], np.int32)\n",
    "\n",
    "# 将数据集分为训练集120条，测试集30条。\n",
    "train_idx = np.random.choice(cfg.data_size, cfg.train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(cfg.data_size)) - set(train_idx)))\n",
    "X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "X_test, Y_test = X[test_idx], Y[test_idx]\n",
    "\n",
    "# 使用MindSpore GeneratorDataset接口将numpy.ndarray类型的数据转换为Dataset\n",
    "def gen_data(X_train, Y_train, epoch_size):\n",
    "    # 生成训练集\n",
    "    XY_train = list(zip(X_train, Y_train))\n",
    "    ds_train = dataset.GeneratorDataset(XY_train, ['x', 'y'])\n",
    "    # 设定数据集大小\n",
    "    # 打乱操作并设定batchsize\n",
    "    ds_train = ds_train.shuffle(buffer_size=cfg.train_size).batch(cfg.batch_size, drop_remainder=True)\n",
    "    # 生成测试集\n",
    "    XY_test = list(zip(X_test, Y_test))\n",
    "    ds_test = dataset.GeneratorDataset(XY_test, ['x', 'y'])\n",
    "    # 设定数据集大小\n",
    "    # 打乱操作并设定batchsize\n",
    "    ds_test = ds_test.shuffle(buffer_size=cfg.test_size).batch(cfg.test_size, drop_remainder=True)\n",
    "    return ds_train, ds_test  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ef1a7-13b7-4f8a-a1f1-a5c82c312dd5",
   "metadata": {},
   "source": [
    "定义训练、评估、测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5fc697b-60c3-4081-8a23-6f90d8b2f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(network, net_opt, ds_train, prefix, directory, print_times):\n",
    "    # 定义网络损失函数\n",
    "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "    # 定义模型\n",
    "    model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={\"acc\"})\n",
    "    # 定义损失值指标\n",
    "    loss_cb = LossMonitor(per_print_times=int(cfg.train_size / cfg.batch_size))\n",
    "    # 设置checkpoint\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                 keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=prefix, directory=directory, config=config_ck)\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    # 训练模型\n",
    "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "    return model\n",
    "\n",
    "class_names=['setosa', 'versicolor', 'virginica']\n",
    "# 评估预测函数\n",
    "def eval_predict(model, ds_test):\n",
    "    # 使用测试集评估模型，打印总体准确率\n",
    "    metric = model.eval(ds_test)\n",
    "    print(metric)\n",
    "    # 预测\n",
    "    test_ = ds_test.create_dict_iterator().__next__()\n",
    "    test = Tensor(test_['x'], mindspore.float32)\n",
    "    predictions = model.predict(test)\n",
    "    predictions = predictions.asnumpy()\n",
    "    true_label = test_['y'].asnumpy()\n",
    "    for i in range(10):\n",
    "        p_np = predictions[i, :]\n",
    "        pre_label = np.argmax(p_np)\n",
    "        print('第' + str(i) + '个sample预测结果：', class_names[pre_label], '   真实结果：', class_names[true_label[i]]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6d747-35b9-4bec-8e83-00d5125105ef",
   "metadata": {},
   "source": [
    "无优化器模型训练并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29092879-cd84-4315-aa7b-477d433ce2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------无优化器--------------------------\n",
      "============== Starting Training ==============\n",
      "epoch: 1 step: 4, loss is 1.0890177488327026\n",
      "epoch: 2 step: 4, loss is 1.108185887336731\n",
      "epoch: 3 step: 4, loss is 1.120065689086914\n",
      "epoch: 4 step: 4, loss is 1.0739997625350952\n",
      "epoch: 5 step: 4, loss is 1.0813523530960083\n",
      "epoch: 6 step: 4, loss is 1.0865776538848877\n",
      "epoch: 7 step: 4, loss is 1.1399807929992676\n",
      "epoch: 8 step: 4, loss is 1.1247919797897339\n",
      "epoch: 9 step: 4, loss is 1.0700039863586426\n",
      "epoch: 10 step: 4, loss is 1.0894412994384766\n",
      "epoch: 11 step: 4, loss is 1.0696682929992676\n",
      "epoch: 12 step: 4, loss is 1.0715069770812988\n",
      "epoch: 13 step: 4, loss is 1.0993870496749878\n",
      "epoch: 14 step: 4, loss is 1.0425852537155151\n",
      "epoch: 15 step: 4, loss is 1.099208116531372\n",
      "epoch: 16 step: 4, loss is 1.1019916534423828\n",
      "epoch: 17 step: 4, loss is 1.0864428281784058\n",
      "epoch: 18 step: 4, loss is 1.1019978523254395\n",
      "epoch: 19 step: 4, loss is 1.1108100414276123\n",
      "epoch: 20 step: 4, loss is 1.088660717010498\n",
      "{'acc': 0.3333333333333333}\n",
      "第0个sample预测结果： virginica    真实结果： setosa\n",
      "第1个sample预测结果： virginica    真实结果： versicolor\n",
      "第2个sample预测结果： virginica    真实结果： virginica\n",
      "第3个sample预测结果： virginica    真实结果： virginica\n",
      "第4个sample预测结果： virginica    真实结果： setosa\n",
      "第5个sample预测结果： virginica    真实结果： setosa\n",
      "第6个sample预测结果： virginica    真实结果： setosa\n",
      "第7个sample预测结果： virginica    真实结果： virginica\n",
      "第8个sample预测结果： virginica    真实结果： versicolor\n",
      "第9个sample预测结果： virginica    真实结果： versicolor\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 20   # 训练20次\n",
    "print('------------------无优化器--------------------------')\n",
    "# 数据\n",
    "ds_train, ds_test = gen_data(X_train, Y_train, epoch_size)  # 生成训练集和测试集\n",
    "# 定义网络并训练\n",
    "network = nn.Dense(cfg.feature_number, cfg.num_class)  # 定义一个全连接网络层，输入特征为4，输出类别为3\n",
    "model = train(network, None, ds_train, \"checkpoint_no_opt\", cfg.out_dir_no_opt, print_times=4)  # 用训练集训练网络，设置网络结构，模型名称，保存路径, print_times\n",
    "# 评估预测\n",
    "eval_predict(model, ds_test)  # 用测试集进行预测 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce027fb-481e-4167-8ca8-bdb4113e0697",
   "metadata": {},
   "source": [
    "SGD优化器模型训练并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5c59abc-8984-42af-b59d-9fc938c2f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------SGD优化器-----------------------\n",
      "============== Starting Training ==============\n",
      "epoch: 1 step: 4, loss is 1.0794405937194824\n",
      "epoch: 2 step: 4, loss is 1.0588743686676025\n",
      "epoch: 3 step: 4, loss is 1.0042811632156372\n",
      "epoch: 4 step: 4, loss is 1.0079346895217896\n",
      "epoch: 5 step: 4, loss is 0.9641113877296448\n",
      "epoch: 6 step: 4, loss is 0.945376455783844\n",
      "epoch: 7 step: 4, loss is 0.943703830242157\n",
      "epoch: 8 step: 4, loss is 0.8927279114723206\n",
      "epoch: 9 step: 4, loss is 0.8863064050674438\n",
      "epoch: 10 step: 4, loss is 0.8643203377723694\n",
      "epoch: 11 step: 4, loss is 0.8530686497688293\n",
      "epoch: 12 step: 4, loss is 0.8531051278114319\n",
      "epoch: 13 step: 4, loss is 0.8509120345115662\n",
      "epoch: 14 step: 4, loss is 0.8578325510025024\n",
      "epoch: 15 step: 4, loss is 0.7968479990959167\n",
      "epoch: 16 step: 4, loss is 0.7877439260482788\n",
      "epoch: 17 step: 4, loss is 0.777549147605896\n",
      "epoch: 18 step: 4, loss is 0.7513393759727478\n",
      "epoch: 19 step: 4, loss is 0.7699323296546936\n",
      "epoch: 20 step: 4, loss is 0.7618291974067688\n",
      "epoch: 21 step: 4, loss is 0.7482919692993164\n",
      "epoch: 22 step: 4, loss is 0.7718892693519592\n",
      "epoch: 23 step: 4, loss is 0.685457170009613\n",
      "epoch: 24 step: 4, loss is 0.6955989599227905\n",
      "epoch: 25 step: 4, loss is 0.73808753490448\n",
      "epoch: 26 step: 4, loss is 0.6942575573921204\n",
      "epoch: 27 step: 4, loss is 0.69647616147995\n",
      "epoch: 28 step: 4, loss is 0.7206736207008362\n",
      "epoch: 29 step: 4, loss is 0.6599401831626892\n",
      "epoch: 30 step: 4, loss is 0.6925424933433533\n",
      "epoch: 31 step: 4, loss is 0.6453061699867249\n",
      "epoch: 32 step: 4, loss is 0.6991602778434753\n",
      "epoch: 33 step: 4, loss is 0.6446717381477356\n",
      "epoch: 34 step: 4, loss is 0.616366446018219\n",
      "epoch: 35 step: 4, loss is 0.6760518550872803\n",
      "epoch: 36 step: 4, loss is 0.6743314266204834\n",
      "epoch: 37 step: 4, loss is 0.6464873552322388\n",
      "epoch: 38 step: 4, loss is 0.6253562569618225\n",
      "epoch: 39 step: 4, loss is 0.6237779855728149\n",
      "epoch: 40 step: 4, loss is 0.5860198736190796\n",
      "epoch: 41 step: 4, loss is 0.7329897284507751\n",
      "epoch: 42 step: 4, loss is 0.6187514066696167\n",
      "epoch: 43 step: 4, loss is 0.5991212725639343\n",
      "epoch: 44 step: 4, loss is 0.6460521221160889\n",
      "epoch: 45 step: 4, loss is 0.5660051703453064\n",
      "epoch: 46 step: 4, loss is 0.6205759048461914\n",
      "epoch: 47 step: 4, loss is 0.6420252919197083\n",
      "epoch: 48 step: 4, loss is 0.5964857339859009\n",
      "epoch: 49 step: 4, loss is 0.5728380680084229\n",
      "epoch: 50 step: 4, loss is 0.5764442682266235\n",
      "epoch: 51 step: 4, loss is 0.6197771430015564\n",
      "epoch: 52 step: 4, loss is 0.5650821924209595\n",
      "epoch: 53 step: 4, loss is 0.5840204358100891\n",
      "epoch: 54 step: 4, loss is 0.6296701431274414\n",
      "epoch: 55 step: 4, loss is 0.605285108089447\n",
      "epoch: 56 step: 4, loss is 0.558627188205719\n",
      "epoch: 57 step: 4, loss is 0.5172578692436218\n",
      "epoch: 58 step: 4, loss is 0.5367629528045654\n",
      "epoch: 59 step: 4, loss is 0.563555121421814\n",
      "epoch: 60 step: 4, loss is 0.5460593104362488\n",
      "epoch: 61 step: 4, loss is 0.5570935606956482\n",
      "epoch: 62 step: 4, loss is 0.5689212679862976\n",
      "epoch: 63 step: 4, loss is 0.6028842329978943\n",
      "epoch: 64 step: 4, loss is 0.524625301361084\n",
      "epoch: 65 step: 4, loss is 0.6736704707145691\n",
      "epoch: 66 step: 4, loss is 0.5181539058685303\n",
      "epoch: 67 step: 4, loss is 0.5741961598396301\n",
      "epoch: 68 step: 4, loss is 0.5007115602493286\n",
      "epoch: 69 step: 4, loss is 0.5106866955757141\n",
      "epoch: 70 step: 4, loss is 0.5465999245643616\n",
      "epoch: 71 step: 4, loss is 0.5440471768379211\n",
      "epoch: 72 step: 4, loss is 0.5027726292610168\n",
      "epoch: 73 step: 4, loss is 0.48585179448127747\n",
      "epoch: 74 step: 4, loss is 0.46101170778274536\n",
      "epoch: 75 step: 4, loss is 0.49925753474235535\n",
      "epoch: 76 step: 4, loss is 0.5219065546989441\n",
      "epoch: 77 step: 4, loss is 0.5704163312911987\n",
      "epoch: 78 step: 4, loss is 0.5265210270881653\n",
      "epoch: 79 step: 4, loss is 0.4377376139163971\n",
      "epoch: 80 step: 4, loss is 0.4802551567554474\n",
      "epoch: 81 step: 4, loss is 0.4734695553779602\n",
      "epoch: 82 step: 4, loss is 0.5346362590789795\n",
      "epoch: 83 step: 4, loss is 0.5255797505378723\n",
      "epoch: 84 step: 4, loss is 0.4551951587200165\n",
      "epoch: 85 step: 4, loss is 0.5261862874031067\n",
      "epoch: 86 step: 4, loss is 0.49947938323020935\n",
      "epoch: 87 step: 4, loss is 0.5560898184776306\n",
      "epoch: 88 step: 4, loss is 0.5224153995513916\n",
      "epoch: 89 step: 4, loss is 0.4872574210166931\n",
      "epoch: 90 step: 4, loss is 0.517804741859436\n",
      "epoch: 91 step: 4, loss is 0.48407113552093506\n",
      "epoch: 92 step: 4, loss is 0.4225689172744751\n",
      "epoch: 93 step: 4, loss is 0.4871309697628021\n",
      "epoch: 94 step: 4, loss is 0.4865882694721222\n",
      "epoch: 95 step: 4, loss is 0.49816009402275085\n",
      "epoch: 96 step: 4, loss is 0.49699267745018005\n",
      "epoch: 97 step: 4, loss is 0.4509745240211487\n",
      "epoch: 98 step: 4, loss is 0.4856172502040863\n",
      "epoch: 99 step: 4, loss is 0.5225311517715454\n",
      "epoch: 100 step: 4, loss is 0.5222590565681458\n",
      "epoch: 101 step: 4, loss is 0.4750794470310211\n",
      "epoch: 102 step: 4, loss is 0.45827922224998474\n",
      "epoch: 103 step: 4, loss is 0.508888840675354\n",
      "epoch: 104 step: 4, loss is 0.47187185287475586\n",
      "epoch: 105 step: 4, loss is 0.5277560949325562\n",
      "epoch: 106 step: 4, loss is 0.5323300957679749\n",
      "epoch: 107 step: 4, loss is 0.3993493318557739\n",
      "epoch: 108 step: 4, loss is 0.483000248670578\n",
      "epoch: 109 step: 4, loss is 0.44187483191490173\n",
      "epoch: 110 step: 4, loss is 0.5410954356193542\n",
      "epoch: 111 step: 4, loss is 0.48445045948028564\n",
      "epoch: 112 step: 4, loss is 0.4814397990703583\n",
      "epoch: 113 step: 4, loss is 0.4395875930786133\n",
      "epoch: 114 step: 4, loss is 0.4518657922744751\n",
      "epoch: 115 step: 4, loss is 0.4963859021663666\n",
      "epoch: 116 step: 4, loss is 0.5049044489860535\n",
      "epoch: 117 step: 4, loss is 0.43343403935432434\n",
      "epoch: 118 step: 4, loss is 0.47661644220352173\n",
      "epoch: 119 step: 4, loss is 0.457043319940567\n",
      "epoch: 120 step: 4, loss is 0.44677817821502686\n",
      "epoch: 121 step: 4, loss is 0.4712730646133423\n",
      "epoch: 122 step: 4, loss is 0.4163855314254761\n",
      "epoch: 123 step: 4, loss is 0.4580915868282318\n",
      "epoch: 124 step: 4, loss is 0.45181167125701904\n",
      "epoch: 125 step: 4, loss is 0.4108874499797821\n",
      "epoch: 126 step: 4, loss is 0.4544726610183716\n",
      "epoch: 127 step: 4, loss is 0.4559800922870636\n",
      "epoch: 128 step: 4, loss is 0.42758092284202576\n",
      "epoch: 129 step: 4, loss is 0.4201578199863434\n",
      "epoch: 130 step: 4, loss is 0.4874686896800995\n",
      "epoch: 131 step: 4, loss is 0.47785866260528564\n",
      "epoch: 132 step: 4, loss is 0.4045100808143616\n",
      "epoch: 133 step: 4, loss is 0.4291006624698639\n",
      "epoch: 134 step: 4, loss is 0.4521176517009735\n",
      "epoch: 135 step: 4, loss is 0.42375749349594116\n",
      "epoch: 136 step: 4, loss is 0.4667450189590454\n",
      "epoch: 137 step: 4, loss is 0.4740206003189087\n",
      "epoch: 138 step: 4, loss is 0.4159938395023346\n",
      "epoch: 139 step: 4, loss is 0.42647144198417664\n",
      "epoch: 140 step: 4, loss is 0.43261826038360596\n",
      "epoch: 141 step: 4, loss is 0.43175560235977173\n",
      "epoch: 142 step: 4, loss is 0.4079344868659973\n",
      "epoch: 143 step: 4, loss is 0.43401771783828735\n",
      "epoch: 144 step: 4, loss is 0.4539257287979126\n",
      "epoch: 145 step: 4, loss is 0.4020383656024933\n",
      "epoch: 146 step: 4, loss is 0.3617978096008301\n",
      "epoch: 147 step: 4, loss is 0.41919833421707153\n",
      "epoch: 148 step: 4, loss is 0.35971787571907043\n",
      "epoch: 149 step: 4, loss is 0.4743351340293884\n",
      "epoch: 150 step: 4, loss is 0.3900088369846344\n",
      "epoch: 151 step: 4, loss is 0.3908982574939728\n",
      "epoch: 152 step: 4, loss is 0.4209238290786743\n",
      "epoch: 153 step: 4, loss is 0.3838057816028595\n",
      "epoch: 154 step: 4, loss is 0.48825836181640625\n",
      "epoch: 155 step: 4, loss is 0.4177292287349701\n",
      "epoch: 156 step: 4, loss is 0.4511025846004486\n",
      "epoch: 157 step: 4, loss is 0.4564926326274872\n",
      "epoch: 158 step: 4, loss is 0.4347154498100281\n",
      "epoch: 159 step: 4, loss is 0.40848782658576965\n",
      "epoch: 160 step: 4, loss is 0.3887527585029602\n",
      "epoch: 161 step: 4, loss is 0.41741326451301575\n",
      "epoch: 162 step: 4, loss is 0.4094972610473633\n",
      "epoch: 163 step: 4, loss is 0.4409938454627991\n",
      "epoch: 164 step: 4, loss is 0.4319663345813751\n",
      "epoch: 165 step: 4, loss is 0.45161062479019165\n",
      "epoch: 166 step: 4, loss is 0.43777063488960266\n",
      "epoch: 167 step: 4, loss is 0.4854694604873657\n",
      "epoch: 168 step: 4, loss is 0.35610613226890564\n",
      "epoch: 169 step: 4, loss is 0.37732985615730286\n",
      "epoch: 170 step: 4, loss is 0.45066988468170166\n",
      "epoch: 171 step: 4, loss is 0.4191838502883911\n",
      "epoch: 172 step: 4, loss is 0.44521281123161316\n",
      "epoch: 173 step: 4, loss is 0.45416802167892456\n",
      "epoch: 174 step: 4, loss is 0.43851178884506226\n",
      "epoch: 175 step: 4, loss is 0.413211852312088\n",
      "epoch: 176 step: 4, loss is 0.41357073187828064\n",
      "epoch: 177 step: 4, loss is 0.3784402012825012\n",
      "epoch: 178 step: 4, loss is 0.39452317357063293\n",
      "epoch: 179 step: 4, loss is 0.48069098591804504\n",
      "epoch: 180 step: 4, loss is 0.3654423952102661\n",
      "epoch: 181 step: 4, loss is 0.4649491608142853\n",
      "epoch: 182 step: 4, loss is 0.3626845180988312\n",
      "epoch: 183 step: 4, loss is 0.3896673619747162\n",
      "epoch: 184 step: 4, loss is 0.363713800907135\n",
      "epoch: 185 step: 4, loss is 0.39659643173217773\n",
      "epoch: 186 step: 4, loss is 0.33680617809295654\n",
      "epoch: 187 step: 4, loss is 0.39250248670578003\n",
      "epoch: 188 step: 4, loss is 0.4507439434528351\n",
      "epoch: 189 step: 4, loss is 0.3705905079841614\n",
      "epoch: 190 step: 4, loss is 0.3825710415840149\n",
      "epoch: 191 step: 4, loss is 0.37192586064338684\n",
      "epoch: 192 step: 4, loss is 0.3651025593280792\n",
      "epoch: 193 step: 4, loss is 0.3460020124912262\n",
      "epoch: 194 step: 4, loss is 0.37824270129203796\n",
      "epoch: 195 step: 4, loss is 0.3862324059009552\n",
      "epoch: 196 step: 4, loss is 0.378018856048584\n",
      "epoch: 197 step: 4, loss is 0.438686341047287\n",
      "epoch: 198 step: 4, loss is 0.4032251536846161\n",
      "epoch: 199 step: 4, loss is 0.4076710343360901\n",
      "epoch: 200 step: 4, loss is 0.3507569432258606\n",
      "epoch: 201 step: 4, loss is 0.34969425201416016\n",
      "epoch: 202 step: 4, loss is 0.4101307988166809\n",
      "epoch: 203 step: 4, loss is 0.34599751234054565\n",
      "epoch: 204 step: 4, loss is 0.39967581629753113\n",
      "epoch: 205 step: 4, loss is 0.3434138000011444\n",
      "epoch: 206 step: 4, loss is 0.48104482889175415\n",
      "epoch: 207 step: 4, loss is 0.4216449558734894\n",
      "epoch: 208 step: 4, loss is 0.35756757855415344\n",
      "epoch: 209 step: 4, loss is 0.39547014236450195\n",
      "epoch: 210 step: 4, loss is 0.30276286602020264\n",
      "epoch: 211 step: 4, loss is 0.37724027037620544\n",
      "epoch: 212 step: 4, loss is 0.4162144064903259\n",
      "epoch: 213 step: 4, loss is 0.39108362793922424\n",
      "epoch: 214 step: 4, loss is 0.4105258285999298\n",
      "epoch: 215 step: 4, loss is 0.3322465717792511\n",
      "epoch: 216 step: 4, loss is 0.41793692111968994\n",
      "epoch: 217 step: 4, loss is 0.35471928119659424\n",
      "epoch: 218 step: 4, loss is 0.3095247149467468\n",
      "epoch: 219 step: 4, loss is 0.3761897683143616\n",
      "epoch: 220 step: 4, loss is 0.3408023416996002\n",
      "epoch: 221 step: 4, loss is 0.3811876177787781\n",
      "epoch: 222 step: 4, loss is 0.33323901891708374\n",
      "epoch: 223 step: 4, loss is 0.3592992424964905\n",
      "epoch: 224 step: 4, loss is 0.3848762512207031\n",
      "epoch: 225 step: 4, loss is 0.3672645390033722\n",
      "epoch: 226 step: 4, loss is 0.4078155755996704\n",
      "epoch: 227 step: 4, loss is 0.3841722905635834\n",
      "epoch: 228 step: 4, loss is 0.4442349076271057\n",
      "epoch: 229 step: 4, loss is 0.3901234269142151\n",
      "epoch: 230 step: 4, loss is 0.29332807660102844\n",
      "epoch: 231 step: 4, loss is 0.36145398020744324\n",
      "epoch: 232 step: 4, loss is 0.3807328939437866\n",
      "epoch: 233 step: 4, loss is 0.3903553783893585\n",
      "epoch: 234 step: 4, loss is 0.3402329981327057\n",
      "epoch: 235 step: 4, loss is 0.38936737179756165\n",
      "epoch: 236 step: 4, loss is 0.3872002959251404\n",
      "epoch: 237 step: 4, loss is 0.36061349511146545\n",
      "epoch: 238 step: 4, loss is 0.41274917125701904\n",
      "epoch: 239 step: 4, loss is 0.2997787892818451\n",
      "epoch: 240 step: 4, loss is 0.3765310049057007\n",
      "epoch: 241 step: 4, loss is 0.39307981729507446\n",
      "epoch: 242 step: 4, loss is 0.3246700167655945\n",
      "epoch: 243 step: 4, loss is 0.26179343461990356\n",
      "epoch: 244 step: 4, loss is 0.3193841278553009\n",
      "epoch: 245 step: 4, loss is 0.34628698229789734\n",
      "epoch: 246 step: 4, loss is 0.3612915277481079\n",
      "epoch: 247 step: 4, loss is 0.3991336226463318\n",
      "epoch: 248 step: 4, loss is 0.3030077815055847\n",
      "epoch: 249 step: 4, loss is 0.37059757113456726\n",
      "epoch: 250 step: 4, loss is 0.3466937243938446\n",
      "epoch: 251 step: 4, loss is 0.3414185345172882\n",
      "epoch: 252 step: 4, loss is 0.32758647203445435\n",
      "epoch: 253 step: 4, loss is 0.37746694684028625\n",
      "epoch: 254 step: 4, loss is 0.3756270110607147\n",
      "epoch: 255 step: 4, loss is 0.3993698060512543\n",
      "epoch: 256 step: 4, loss is 0.33180275559425354\n",
      "epoch: 257 step: 4, loss is 0.3700159788131714\n",
      "epoch: 258 step: 4, loss is 0.32215309143066406\n",
      "epoch: 259 step: 4, loss is 0.4112101197242737\n",
      "epoch: 260 step: 4, loss is 0.3556874990463257\n",
      "epoch: 261 step: 4, loss is 0.396845281124115\n",
      "epoch: 262 step: 4, loss is 0.3292539715766907\n",
      "epoch: 263 step: 4, loss is 0.3316640853881836\n",
      "epoch: 264 step: 4, loss is 0.3099660277366638\n",
      "epoch: 265 step: 4, loss is 0.404312402009964\n",
      "epoch: 266 step: 4, loss is 0.33645737171173096\n",
      "epoch: 267 step: 4, loss is 0.3839254081249237\n",
      "epoch: 268 step: 4, loss is 0.3837067484855652\n",
      "epoch: 269 step: 4, loss is 0.32334163784980774\n",
      "epoch: 270 step: 4, loss is 0.39414310455322266\n",
      "epoch: 271 step: 4, loss is 0.34413179755210876\n",
      "epoch: 272 step: 4, loss is 0.35698598623275757\n",
      "epoch: 273 step: 4, loss is 0.38143444061279297\n",
      "epoch: 274 step: 4, loss is 0.38704195618629456\n",
      "epoch: 275 step: 4, loss is 0.34195414185523987\n",
      "epoch: 276 step: 4, loss is 0.29983243346214294\n",
      "epoch: 277 step: 4, loss is 0.34272149205207825\n",
      "epoch: 278 step: 4, loss is 0.3385179340839386\n",
      "epoch: 279 step: 4, loss is 0.3796268105506897\n",
      "epoch: 280 step: 4, loss is 0.310369610786438\n",
      "epoch: 281 step: 4, loss is 0.2832501530647278\n",
      "epoch: 282 step: 4, loss is 0.3591035306453705\n",
      "epoch: 283 step: 4, loss is 0.36389610171318054\n",
      "epoch: 284 step: 4, loss is 0.4004814326763153\n",
      "epoch: 285 step: 4, loss is 0.28453901410102844\n",
      "epoch: 286 step: 4, loss is 0.36725208163261414\n",
      "epoch: 287 step: 4, loss is 0.3559984266757965\n",
      "epoch: 288 step: 4, loss is 0.32074323296546936\n",
      "epoch: 289 step: 4, loss is 0.35021406412124634\n",
      "epoch: 290 step: 4, loss is 0.3428625762462616\n",
      "epoch: 291 step: 4, loss is 0.3434334695339203\n",
      "epoch: 292 step: 4, loss is 0.3725176751613617\n",
      "epoch: 293 step: 4, loss is 0.34586000442504883\n",
      "epoch: 294 step: 4, loss is 0.3729926347732544\n",
      "epoch: 295 step: 4, loss is 0.350301057100296\n",
      "epoch: 296 step: 4, loss is 0.3448609411716461\n",
      "epoch: 297 step: 4, loss is 0.3580560088157654\n",
      "epoch: 298 step: 4, loss is 0.3347511887550354\n",
      "epoch: 299 step: 4, loss is 0.4003637731075287\n",
      "epoch: 300 step: 4, loss is 0.3485199511051178\n",
      "{'acc': 1.0}\n",
      "第0个sample预测结果： virginica    真实结果： virginica\n",
      "第1个sample预测结果： setosa    真实结果： setosa\n",
      "第2个sample预测结果： versicolor    真实结果： versicolor\n",
      "第3个sample预测结果： setosa    真实结果： setosa\n",
      "第4个sample预测结果： setosa    真实结果： setosa\n",
      "第5个sample预测结果： virginica    真实结果： virginica\n",
      "第6个sample预测结果： versicolor    真实结果： versicolor\n",
      "第7个sample预测结果： setosa    真实结果： setosa\n",
      "第8个sample预测结果： versicolor    真实结果： versicolor\n",
      "第9个sample预测结果： virginica    真实结果： virginica\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------SGD-------------------------------------\n",
    "epoch_size = 300  # 训练300次\n",
    "lr = 0.01\n",
    "print('-------------------SGD优化器-----------------------')\n",
    "# 数据\n",
    "ds_train, ds_test = gen_data(X_train, Y_train, epoch_size) # 生成训练集和测试集\n",
    "# 定义网络并训练、测试、预测\n",
    "network = nn.Dense(cfg.feature_number, cfg.num_class)  # 定义一个全连接网络层，输入特征为4，输出类别为3\n",
    "net_opt = nn.SGD(network.trainable_params(), lr)  # 用SGD优化器进行优化 \n",
    "model = train(network, net_opt, ds_train, \"checkpoint_sgd\", cfg.out_dir_sgd, 40)  # 用训练集训练网络，设置网络结构，优化器，模型名称，保存路径, print_times\n",
    "# 评估预测\n",
    "eval_predict(model, ds_test) # 用测试集进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89719a7e-d7ef-4300-81b7-d3458ea81c4a",
   "metadata": {},
   "source": [
    "Momentum优化器模型训练并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27dab98-f4de-460a-aa54-2ddc63f48b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Momentum优化器-----------------------\n",
      "============== Starting Training ==============\n",
      "epoch: 1 step: 4, loss is 1.0351159572601318\n",
      "epoch: 2 step: 4, loss is 0.9739065170288086\n",
      "epoch: 3 step: 4, loss is 0.997841477394104\n",
      "epoch: 4 step: 4, loss is 0.665257453918457\n",
      "epoch: 5 step: 4, loss is 0.6971848607063293\n",
      "epoch: 6 step: 4, loss is 0.6415892243385315\n",
      "epoch: 7 step: 4, loss is 0.5625832080841064\n",
      "epoch: 8 step: 4, loss is 0.5181046724319458\n",
      "epoch: 9 step: 4, loss is 0.497139573097229\n",
      "epoch: 10 step: 4, loss is 0.4468664228916168\n",
      "epoch: 11 step: 4, loss is 0.49530303478240967\n",
      "epoch: 12 step: 4, loss is 0.4412528872489929\n",
      "epoch: 13 step: 4, loss is 0.4025491178035736\n",
      "epoch: 14 step: 4, loss is 0.4438770115375519\n",
      "epoch: 15 step: 4, loss is 0.38906240463256836\n",
      "epoch: 16 step: 4, loss is 0.43213075399398804\n",
      "epoch: 17 step: 4, loss is 0.4019095301628113\n",
      "epoch: 18 step: 4, loss is 0.2954254746437073\n",
      "epoch: 19 step: 4, loss is 0.38437923789024353\n",
      "epoch: 20 step: 4, loss is 0.3326970934867859\n",
      "{'acc': 1.0}\n",
      "第0个sample预测结果： versicolor    真实结果： versicolor\n",
      "第1个sample预测结果： versicolor    真实结果： versicolor\n",
      "第2个sample预测结果： setosa    真实结果： setosa\n",
      "第3个sample预测结果： setosa    真实结果： setosa\n",
      "第4个sample预测结果： virginica    真实结果： virginica\n",
      "第5个sample预测结果： setosa    真实结果： setosa\n",
      "第6个sample预测结果： virginica    真实结果： virginica\n",
      "第7个sample预测结果： versicolor    真实结果： versicolor\n",
      "第8个sample预测结果： virginica    真实结果： virginica\n",
      "第9个sample预测结果： setosa    真实结果： setosa\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 20  # 训练20次\n",
    "lr = 0.01  # 学习率为0.01\n",
    "print('-------------------Momentum优化器-----------------------')\n",
    "# 数据\n",
    "ds_train, ds_test = gen_data(X_train, Y_train, epoch_size)  # 生成训练集和测试集\n",
    "# 定义网络并训练\n",
    "network = nn.Dense(cfg.feature_number, cfg.num_class) # 定义一个全连接网络层，输入特征为4，输出类别为3\n",
    "net_opt = nn.Momentum(network.trainable_params(), lr, 0.9)   # 用 momentum 优化器进行优化，学习率为0.01，动量大小为0.9\n",
    "model = train(network, net_opt, ds_train, \"checkpoint_momentum\", cfg.out_dir_momentum, 4)  # 用训练集训练网络，设置网络结构，优化器，模型名称，保存路径, print_times\n",
    "# 评估预测\n",
    "eval_predict(model, ds_test)  # 用测试集进行预测  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec302db7-fb95-4c6b-ada1-1af655e14a00",
   "metadata": {},
   "source": [
    "Adam优化器模型训练并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3d0e36d-bb31-404b-93b9-49d0c0bf1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Adam优化器--------------------------\n",
      "============== Starting Training ==============\n",
      "epoch: 1 step: 4, loss is 0.8355636596679688\n",
      "epoch: 2 step: 4, loss is 0.9874771237373352\n",
      "epoch: 3 step: 4, loss is 1.1438740491867065\n",
      "epoch: 4 step: 4, loss is 0.6680456399917603\n",
      "epoch: 5 step: 4, loss is 0.4415942430496216\n",
      "epoch: 6 step: 4, loss is 0.9772436618804932\n",
      "epoch: 7 step: 4, loss is 0.4867591857910156\n",
      "epoch: 8 step: 4, loss is 0.4729108512401581\n",
      "epoch: 9 step: 4, loss is 0.7108497023582458\n",
      "epoch: 10 step: 4, loss is 0.409839004278183\n",
      "epoch: 11 step: 4, loss is 0.41292107105255127\n",
      "epoch: 12 step: 4, loss is 0.4746319055557251\n",
      "epoch: 13 step: 4, loss is 0.2644176781177521\n",
      "epoch: 14 step: 4, loss is 0.3061882555484772\n",
      "epoch: 15 step: 4, loss is 0.2752925455570221\n",
      "{'acc': 1.0}\n",
      "第0个sample预测结果： versicolor    真实结果： versicolor\n",
      "第1个sample预测结果： virginica    真实结果： virginica\n",
      "第2个sample预测结果： setosa    真实结果： setosa\n",
      "第3个sample预测结果： versicolor    真实结果： versicolor\n",
      "第4个sample预测结果： virginica    真实结果： virginica\n",
      "第5个sample预测结果： virginica    真实结果： virginica\n",
      "第6个sample预测结果： virginica    真实结果： virginica\n",
      "第7个sample预测结果： virginica    真实结果： virginica\n",
      "第8个sample预测结果： versicolor    真实结果： versicolor\n",
      "第9个sample预测结果： virginica    真实结果： virginica\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 15  # 训练15次\n",
    "lr = 0.1  # 学习率为0.1, 动态学习率\n",
    "print('------------------Adam优化器--------------------------')\n",
    "# 数据\n",
    "ds_train, ds_test = gen_data(X_train, Y_train, epoch_size)  # 生成训练集和测试集\n",
    "# 定义网络并训练\n",
    "network = nn.Dense(cfg.feature_number, cfg.num_class)  # 定义一个全连接网络层，输入特征为4，输出类别为3\n",
    "net_opt = nn.Adam(network.trainable_params(), learning_rate=lr)  # 用 Adam 优化器进行优化，学习率为0.1\n",
    "model = train(network, net_opt, ds_train, \"checkpoint_adam\", cfg.out_dir_adam, 4)  # 用训练集训练网络，设置网络结构，优化器，模型名称，保存路径, print_times\n",
    "# 评估预测\n",
    "eval_predict(model, ds_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf53c04-5de1-4eac-88c1-5d7a26379e47",
   "metadata": {},
   "source": [
    "查看保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde40b2a-b899-4892-89e2-70a357a53cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint_adam-graph.meta', 'checkpoint_adam-15_4.ckpt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./model_iris/adam') # 查看保存的模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
