# 项目报告

## 基本框架介绍

### pyTorch

PyTorch是一个开源的机器学习框架，它基于Python语言，并提供了丰富的工具和库来支持构建、训练和部署深度学习模型

### monai

MONAI（Medical Open Network for AI）是一个用于医学图像分析的开源深度学习框架，旨在加速医学图像处理和人工智能（AI）模型的开发和部署，提供了丰富的工具和功能，用于处理医学图像数据、构建深度学习模型，并进行模型的训练、验证和推理。

MONAI框架包含以下组件和功能：

1. `数据预处理`：MONAI提供了丰富的医学图像数据预处理工具，包括图像的加载、裁剪、缩放、旋转、翻转、标准化、直方图均衡化等操作，用于准备用于深度学习模型的训练数据。
2. `数据加载和处理`：MONAI支持常见的医学图像数据格式，如NIfTI、DICOM等，并提供了用于数据加载和处理的工具，例如数据集类（Dataset）、数据加载器（DataLoader），以便在训练和推理过程中高效地处理大规模医学图像数据。
3. `深度学习模型`：MONAI支持多种常用的深度学习模型，如卷积神经网络（Convolutional Neural Networks, CNNs）、生成对抗网络（Generative Adversarial Networks, GANs）、循环神经网络（Recurrent Neural Networks, RNNs）等，并提供了用于构建和配置这些模型的工具，如模型定义（Module）、层（Layers）、损失函数（Losses）等。
4. `模型训练和验证`：MONAI提供了用于模型训练和验证的高级工具，包括模型训练器（Trainer）、验证器（Validator）、学习率策略（Learning Rate Schedule）等，用于实现自定义的训练和验证逻辑，例如批量处理、学习率调整和模型性能评估。



## 项目思路![image-20230520131333783](https://raw.githubusercontent.com/starry521/CloudImg/main/202305201314611.png)



## 数据集处理

### **预处理**

moai提供了丰富的数据增强的transform（变换）来处理医学图像数据

本次项目transform的使用说明：

- ScaleIntensityRanged（强度缩放）：

​		医学图像数据不同于自然图像，其像素值取值范围等同于有符号十六位整数，根据数据集的情况来看，用固定值截断的方法将其限制在[-300, 300]的范围内

- SpatialPadd（空间填充）

    每个图像的形状一般都不相同，设置填充形状为[128, 128, 128]，在不足的维度上进行填充

- RandCropByPosNegLabeld（随机裁剪）

    图像太大，整个用于训练速度很慢，进行裁剪，裁剪形状为[128, 128, 128]，裁剪出4个子样本

- Resized（调整大小）

    将图像以插值的方式调整到指定的大小[128, 128, 128]

- CropForegroundd（裁剪前景）

    裁剪出图像的前景，并且设置在裁出的前景周围填充30，每个图像裁剪结果不一致

    

一阶段方法：

- 训练集：ScaleIntensityRanged、SpatialPadd、RandCropByPosNegLabeld

- 验证集：ScaleIntensityRanged

- 测试集：ScaleIntensityRanged

    

两阶段方法：

- 粗分割：提前将origin目录的原图像Resized，存入resized目录，训练预处理只有ScaleIntensityRanged

- 细分割：提前将origin目录的原图像foreground，存入foreground目录，训练预处理ScaleIntensityRanged + Crop

    

### **划分**

一阶段：

- 训练集和验证集共131个样本，训练集：验证集=3：1=78：26，剩下27不处理（内存空间不足的问题）

- 测试集共70个样本



两阶段：

- 训练集和验证集共131个样本，训练集：验证集=4：1=104：27，全部使用

- 测试集共70个样本

    

### **加载**

- 使用monai中Dataset和DataLoader两个组件进行数据的预处理和加载

​		其中，Dataset是基本类，训练集采用CacheDataset（提供数据缓存机制的扩展类）。由于训练集数据每轮训练都要用，它会一次性将数据全部加载到内存中，并且在CPU第一次加载数据时将变换后的数据缓存起来，避免重复的数据加载，访问效率更高。

​		而对于验证集，就是用普通的Dataset，验证一轮加载一次（访问频率低），其次是缓存空间有限而图像大（nii.gz文件占用空间在100M到几个G）

- batch_size设置为1，避免对GPU显存的过高占用



## 模型结构

### unet

`U-net`是Encoder-Decoder的结构，Encoder部分提取特征，Decoder部分恢复原始分辨率。

![image-20230519162434138](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191624278.png)

图例：

- 深蓝色箭头：`3*3`卷积和ReLU激活

- 红色箭头：`2*2`最大池化，即下采样

- 绿色箭头：`2*2`反卷积，即上采样

- 灰色箭头：复制与裁剪

- 青色箭头：`1*1`卷积

    

解析：

- 左侧是收缩路径，每层两次（卷积+ReLU）和一次max池化操作（下采样），每次下采样特征通道数量翻一倍。

- 右侧是对称扩展路径，每层一次上采样和两次（卷积+ReLU），将特征通道数量减半，并且拼接融合收缩路径同层的特征图。

U-net通过通道的拼接保留了更多的维度/位置 信息，结合浅层特征和深层特征

基本网络为4层或者5层，模型整体是对称的，适于模块化



### 构建

- 卷积层参数初始化使用kaiming初始化方法：

```python
nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
```

​		以均值为0、标准差为计算得到的标准差值来初始化输入参数的权重，指定ReLU激活函数以更准确地计算标准差，使模型在前向传播过程中保持方差不变，以减少梯度消失或梯度爆炸的问题。

- 基本模块：
  1. `_ConvINReLU3D`，进行`conv+norm+drop+relu`的处理
  2. `_ConvIN3D`，进行`conv+norm`的处理
- 编码器模块和解码器模块：
  1. `UnetTwoLayerBlock`：两次`_ConvINReLU3D`
  2. `ResTwoLayerConvBlock`：`residual_unit`进行`_ConvINReLU3D + _ConvIN3D`的处理，`shortcut_unit`进行`_ConvIN3D`的处理，然后进行相加
- 模型有五层，每层的通道数设置为[16, 32, 64, 128, 256]
- 编码阶段--进行四次编码+池化的操作：

```python
x = self.conv0_0(x)
x1_0 = self.conv1_0(self.pool(x))
x2_0 = self.conv2_0(self.pool(x1_0))
x3_0 = self.conv3_0(self.pool(x2_0))
x4_0 = self.conv4_0(self.pool(x3_0))
```

- 解码阶段--再进行四次解码+（上采样+拼接）的操作：

```
x3_0 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))
x2_0 = self.conv2_2(torch.cat([x2_0, self.up(x3_0)], 1))
x1_0 = self.conv1_3(torch.cat([x1_0, self.up(x2_0)], 1))
x = self.conv0_4(torch.cat([x, self.up(x1_0)], 1))
```

- 最后进行主点卷积，进行不同通道特征图的融合

```python
x = self.final(x)
```



## 训练组件

### 优化器

使用monai提供的Novograd优化器

```python
optimizer = Novograd(model.parameters(), lr=args.lr)
```

两个特点：自适应学习率和梯度修剪

- Novograd通过根据梯度的方向和大小来自适应地调整学习率，以更好地适应不同参数的变化情况，这使得Novograd在训练深度学习模型时更容易找到全局最优解或更接近最优解的局部最优解。

- 它引入了一种新的正则化项，称为"orthogonal regularization"（正交正则化）。这个正则化项通过鼓励模型参数之间的正交性来提高模型的泛化能力。正交正则化可以使模型的参数更加均衡，减少过拟合的风险。



### 学习率调度器

使用torch提供的CosineAnnealingWarmRestarts（余弦退火策略）学习率调度器，

```python
scheduler = CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=5, T_mult=3)
```

其中，T_0是学习率第一次达到最大值的epoch，T_mult控制学习率变化周期，设置为3，分别在epoch为5,20,50....时达到最大值

学习率变化图示（T_mult=2时）：

**![image-20220429184820914](http://img.peterli.club/img/image-20220429184820914.png)**







- Novograd优化器则可以自适应地调整每个参数的学习率，以更好地适应不同参数的变化情况
- CosineAnnealingWarmRestarts帮助模型在训练初期更快地收敛，并在后续阶段进行更细致的调整。它可以有效地帮助模型跳出局部最优解并找到更优的全局最优解

通过Novograd+CosineAnnealingWarmRestarts的组合， 可以提高模型的训练效果，并更快地达到更好的性能水平。





### 评价指标

使用monai提供的DiceMetric

```python
dice_metric = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)
```

每个批次有多个滑动窗口做验证，取dice系数的平均值

对于二分类问题，一般预测值分为以下几种:

- TP: true positive，真阳性，预测是阳性，实际也是正例。

- TN: true negative，真阴性，预测是阴性，实际也是负例。

- FP: false positive，假阳性，预测是阳性，实际是负例。

- FN: false negative，假阴性，预测是阴性，实际是正例。

  

![img](https://pic1.zhimg.com/80/v2-dbd8975f8f287cb547809807f463a1cc_720w.webp)



dice系数：
$$
dice = \frac{2TP}{2TP+FP+FN}
$$





### 损失函数

使用monai提供的DiceLoss

```python
loss_function = DiceLoss(to_onehot_y=False, sigmoid=True, include_background=False)
```



![image-20230519162844188](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191628228.png)

其中 |X⋂Y| 是X和Y之间的交集， |X| + |Y| 表示X和Y之间的并集，分子乘2为了保证分母重复计算后取值范围在 [0,1] 之间





## 训练

```
model.train()
total_loss = 0
number = 0
epoch_start = time.time()

for _,batch  in enumerate(data_loader):

    # 获取图像和标签
    images, labels = batch['image'].to(device), batch['label'].to(device)  # [n,c*sw,w,h,d]

    # 每个batch梯度清0
    optimizer.zero_grad()

    # forward + loss
    outputs = model(images)
    loss = loss_function(outputs, labels)

    # 反向传播 + 优化器更新参数
    loss.backward()
    optimizer.step()

    # 更新总loss和总batch数
    total_loss += loss.item()
    number += 1
    
    # 清空占用空间
    del images, labels
    torch.cuda.empty_cache()
    
# 更新学习率
scheduler.step()

# 计算每轮平均loss
epoch_mean_loss = total_loss / number
```



## 推理

使用滑动窗口`sliding_window_inference`进行推理

```
model.eval()
total_dice = 0
number = 0

# 定义后处理compose
post_label, post_pred = post_ways(num_classes)

with torch.no_grad():   #不计算梯度

    for _, batch in enumerate(data_loader):

        # 获取图像和标签
        images, labels = batch['image'].to(device), batch['label'].to(device)

        # forward
        outputs = sliding_window_inference(images, roi_size, sw_batch_size, model)

        # 计算评价指标
        outputs = [post_pred(i) for i in decollate_batch(outputs)]
        labels = [post_label(i) for i in decollate_batch(labels)]
        dice = dice_metric(y_pred=outputs, y=labels)

        # 计算总dice系数和总batch数
        total_dice += dice.item()
        number = number + 1

        # 清空占用空间
        del images, labels
        torch.cuda.empty_cache()

    # 计算平均dice系数
    epoch_mean_dice = total_dice / number
```



测试进行推理要保存分割结果



## 结果

### 一阶段

#### 第一次结果

- 总样本=131，训练集：验证集=3：1，分别为78：26，空闲27个样本
- 使用`UnetTwoLayerConvBlock`模块作为编码和解码模块
- 学习率初始设置为0.008，学习率调度器为余弦退火CosineAnnealingWarmRestarts，T_0=5，T_mult=3
- 训练轮数为50，验证间隔轮数为10

![image-20230519162921581](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191629676.png)

![image-20230519162944636](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191629694.png)



#### 第二次结果

- 使用`ResTwoLayerConvBlock`模块作为编码和解码模块
- 总样本=131，训练集：验证集=3：1，分别为78：26，空闲27个样本
- 学习率初始设置为0.004，学习率调度器为余弦退火CosineAnnealingWarmRestarts，T_0=5，T_mult=3
- 训练轮数为200，验证间隔轮数为10

![image-20230519163649800](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191636898.png)

![image-20230519163735053](https://raw.githubusercontent.com/starry521/CloudImg/main/202305191637151.png)



### 两阶段

#### 粗分割模型训练

![image-20230520210628068](C:\Users\JOHN\Pictures\粗模型)

训练100轮，训练时间大幅减少，准确率大幅提升，作为粗分割的模型比较合适



#### 细分割模型训练

![image-20230521102839458](C:\Users\JOHN\Pictures\细模型)



内存和GPU占用情况：内存没有负担，GPU显存压力还是大

![image-20230520085037363](https://raw.githubusercontent.com/starry521/CloudImg/main/202305200850439.png)





## 结果分析及改进思路（2页）

### 结果分析

- 训练轮数的增加有助于模型尽可能找到全局最优解，从50轮到200轮的结果可以看出，dice系数有了明显提升，但是训练轮数的次数提高使得训练所需时长大幅提升，在有限的时间内不是好方法

- 学习率的适当降低有助于模型找到最优解，从0.008到0.004，高学习率会使得模型直接跳过最优解，导致没有记录到最优解，但是低的学习率也会导致模型寻找解的速度变慢，需要多次实验权衡

- 使用ResNet的残差模块去替换Unet的编码和解码模块，可以看到dice系数有提升，但与此同时模型的复杂度也提升了，对GPU的要求提高（24G的显存勉强够用），训练时所需长也适当增加，这种方法有效

- 从一阶段方法转到两阶段方法，不仅准确率大幅提升，训练时间也大幅减少，对内存和GPU的压力也大幅降低。



### 改进思路

- 进行更有效的数据增强方法，如扭曲、随机旋转等，在本次项目中只是使用了空间填充和随机裁剪两个方法结合控制输入图像的形状相同
- 采用其他的学习率调度器，在本次项目中使用了余弦退火重启策略，可以尝试线性预热余弦退火等其他策略验证效果
- 增加`unet`模型的每层的通道数，在本次项目中是[16, 32, 64, 128, 256]，论文里面是[64, 128, 256, 512, 1024]，更多的通道意味着提取的特征更加全面和细致，但是模型的复杂度也会对应提高。



## 项目总结







